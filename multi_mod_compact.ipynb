{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiple models in one GPU\n",
    "\n",
    "This module contains different models that will be trained using one GPU. There are `num_arch` numbers of architecture constructed, each of which is assigned with `num_opt` numbers of optimizers. This gives us a total of `num_models` models to be trained.<br>\n",
    "Run the function  `multi_mod_training()` in a separate console so you can still import the module to check the result of training even before the `max_epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import chainer\n",
    "from chainer import configuration\n",
    "from chainer.dataset import convert\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import serializers\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import random\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign values for the training parameters `batchsize` and `max_epoch`. Specify also the name of `directory` where the model and optimizers, together with the testing and training informations are to be saved.\n",
    "\n",
    "If you wish to resume an interrupted run, simply set `resume=True`. Keep in mind that you should have the same `directory` as the previous training. Also, the `max_epoch` is now the new `max_epoch` plus the previously interrupted epoch. If you want to start a new run, then simply set `resume=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1600\n",
    "max_epoch = 3000\n",
    "directory = 'generalization'\n",
    "resume = False\n",
    "\n",
    "gpu_id = 0\n",
    "device = chainer.get_device(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your own neural network architecture. Specify the number of architectures that you have created in `num_arch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP1(chainer.Chain):\n",
    "    #Two hidden layers with 250-100 nodes\n",
    "    def __init__(self):\n",
    "        super(MLP1, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(200, 250, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l2 = L.Linear(250, 100, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l3 = L.Linear(100,   3, nobias=False, initialW=None, initial_bias=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "class MLP2(chainer.Chain):\n",
    "    #Three hidden layers with 250-100-50 nodes\n",
    "    def __init__(self):\n",
    "        super(MLP2, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(200, 250, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l2 = L.Linear(250, 100, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l3 = L.Linear(100,  50, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l4 = L.Linear(50,    3, nobias=False, initialW=None, initial_bias=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h3 = F.relu(self.l3(h2))\n",
    "        return self.l4(h3)\n",
    "\n",
    "class MLP3(chainer.Chain):\n",
    "    #Three hidden layers with 250-250-250 nodes\n",
    "    def __init__(self):\n",
    "        super(MLP3, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(200, 250, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l2 = L.Linear(250, 250, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l3 = L.Linear(250, 250, nobias=False, initialW=None, initial_bias=None)\n",
    "            self.l4 = L.Linear(250,   3, nobias=False, initialW=None, initial_bias=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        h3 = F.relu(self.l3(h2))\n",
    "        return self.l4(h3)    \n",
    "    \n",
    "num_arch = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the optimizer that you want to test and specify in `num_opt` the number of optimizer per architecture. That is, for each architecture we have more than one optimizers. The total number of models to be trained, `num_models`, is equal to `num_arch` $\\times$ `num_opt` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link each model to a classifier\n",
    "model1 = L.Classifier(MLP1())\n",
    "model2 = L.Classifier(MLP2())\n",
    "model3 = L.Classifier(MLP3())\n",
    "\n",
    "model4 = L.Classifier(MLP1())\n",
    "model5 = L.Classifier(MLP2())\n",
    "model6 = L.Classifier(MLP3())\n",
    "\n",
    "model1.to_device(device)\n",
    "model2.to_device(device)\n",
    "model3.to_device(device)\n",
    "model4.to_device(device)\n",
    "model5.to_device(device)\n",
    "model6.to_device(device)\n",
    "\n",
    "#Setup the optimizer\n",
    "optimizer1 = chainer.optimizers.Adam()\n",
    "optimizer2 = chainer.optimizers.Adam()\n",
    "optimizer3 = chainer.optimizers.Adam()\n",
    "\n",
    "optimizer4 = chainer.optimizers.AMSGrad()\n",
    "optimizer5 = chainer.optimizers.AMSGrad()\n",
    "optimizer6 = chainer.optimizers.AMSGrad()\n",
    "\n",
    "optimizer1.setup(model1)\n",
    "optimizer2.setup(model2)\n",
    "optimizer3.setup(model3)\n",
    "\n",
    "optimizer4.setup(model4)\n",
    "optimizer5.setup(model5)\n",
    "optimizer6.setup(model6)\n",
    "\n",
    "num_opt = 2\n",
    "\n",
    "num_models = num_arch * num_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can now be used to execute the training in one GPU. The `train_mnist_custom_loop.py` is modified to accommodate multiple models in one GPU. Simply run `multi_mod_training()` in a separate console so this module can still be imported in a different notebook. Only the training epoch and time elapsed are printed but you may check the training and testing accuracies in the `experiment` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def multi_mod_training():\n",
    "    #Train num_models different models in a single GPU\n",
    "    #using the modified manual MNIST training loop.\n",
    "    #Variable names for (each model) are generated dynamically using exec()\n",
    "    \n",
    "    #Load Classification dataset\n",
    "    train = pickle.load(open('chainer_train.pkl','rb'))\n",
    "    test = pickle.load(open('chainer_test.pkl','rb'))\n",
    "    \n",
    "    #Define Iterator\n",
    "    train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "    test_iter = chainer.iterators.SerialIterator(test, batchsize,\n",
    "                                             repeat=False, shuffle=False)\n",
    "    \n",
    "    out = directory\n",
    "    if not os.path.isdir(out):\n",
    "        os.makedirs(out)\n",
    "\n",
    "\n",
    "    \n",
    "    if resume==True:\n",
    "        log = open(os.path.join(out,'training_log.txt'),'a+')\n",
    "        for modndx in range(num_models):\n",
    "            #Load training and testing accuracies of the earlier run\n",
    "            exec('training_accu{}=pickle.load(open(os.path.join(out,\"training_accu{}.pkl\"),\"rb\"))'.format(modndx+1,modndx+1))\n",
    "            exec('testing_accu{}=pickle.load(open(os.path.join(out,\"testing_accu{}.pkl\"),\"rb\"))'.format(modndx+1,modndx+1))\n",
    "            #Load training and testing losses of the earlier run\n",
    "            exec('training_loss{}=pickle.load(open(os.path.join(out,\"training_loss{}.pkl\"),\"rb\"))'.format(modndx+1,modndx+1))\n",
    "            exec('testing_loss{}=pickle.load(open(os.path.join(out,\"testing_loss{}.pkl\"),\"rb\"))'.format(modndx+1,modndx+1)) \n",
    "            #Load the model and the optimizer's previous state\n",
    "            exec('serializers.load_npz(os.path.join(out,\"MLP{}.model\"), model{})'.format(modndx+1,modndx+1))\n",
    "            exec('serializers.load_npz(os.path.join(out,\"MLP{}.state\"), optimizer{})'.format(modndx+1,modndx+1))\n",
    "        #I need this to assign value to last epoch\n",
    "        training_accu1 = pickle.load(open(os.path.join(out,\"training_accu1.pkl\"),\"rb\"))\n",
    "    elif resume==False:\n",
    "        log = open(os.path.join(out,'training_log.txt'),'w+')\n",
    "        log = open(os.path.join(out,'training_log.txt'),'a+')\n",
    "        for modndx in range(num_models):\n",
    "            exec('training_loss{} = []'.format(modndx+1))\n",
    "            exec('training_accu{} = []'.format(modndx+1))\n",
    "            exec('testing_loss{} = []'.format(modndx+1))\n",
    "            exec('testing_accu{} = []'.format(modndx+1))\n",
    "        #I need this to assign value to last epoch\n",
    "        training_accu1 = [] \n",
    "    \n",
    "    last_epoch = len(training_accu1)\n",
    "        \n",
    "    \n",
    "    time_start = time.time()    \n",
    "    test_count = len(test)\n",
    "    \n",
    "    #Initialize training\n",
    "    train_count = 0\n",
    "    for modndx in range(num_models):\n",
    "        exec('sum{}_loss = 0'.format(modndx+1))\n",
    "        exec('sum{}_accu = 0'.format(modndx+1))\n",
    "        \n",
    "    #---------------------------start training epoch----------------------------------------------\n",
    "    while train_iter.epoch < max_epoch:\n",
    "        batch = train_iter.next()\n",
    "        x, t = convert.concat_examples(batch, device)\n",
    "        train_count += len(t)\n",
    "        \n",
    "        for modndx in range(num_models):\n",
    "            #Update network's parameters using forward pass and \n",
    "            #backpropagation for each model            \n",
    "            exec('optimizer{}.update(model{}, x, t)'.format(modndx+1,modndx+1))\n",
    "            #Calculate training loss and accuracy\n",
    "            exec('sum{}_loss += float(model{}.loss.array)*len(t)'.format(modndx+1,modndx+1))\n",
    "            exec('sum{}_accu += float(model{}.accuracy.array)*len(t)'.format(modndx+1,modndx+1))\n",
    "    #-----------------------end of one epoch----------------------------------------------------\n",
    "        \n",
    "        if train_iter.is_new_epoch:\n",
    "            for modndx in range(num_models):\n",
    "                #Record training loss and accuracy for each model\n",
    "                exec('training_loss{}.append(sum{}_loss/train_count)'.format(modndx+1,modndx+1))\n",
    "                exec('training_accu{}.append(sum{}_accu/train_count)'.format(modndx+1,modndx+1))\n",
    "                #Initialize loss and accuracy for testing\n",
    "                exec('sum{}_loss = 0'.format(modndx+1))\n",
    "                exec('sum{}_accu = 0'.format(modndx+1))\n",
    "            \n",
    "            #Enable evaluation mode\n",
    "            with configuration.using_config('train', False):\n",
    "                #This is optional but can reduce computational overhead\n",
    "                with chainer.using_config('enable_backprop', False):\n",
    "                    for batch in test_iter:\n",
    "                        x, t = convert.concat_examples(batch, device)\n",
    "                        \n",
    "                        #Calculate testing loss and accuracy\n",
    "                        for modndx in range(num_models):\n",
    "                            exec('loss{} = model{}(x,t)'.format(modndx+1,modndx+1))\n",
    "                            exec('sum{}_loss += float(loss{}.array)*len(t)'.format(modndx+1,modndx+1))\n",
    "                            exec('sum{}_accu += (model{}.accuracy.array)*len(t)'.format(modndx+1,modndx+1))\n",
    "            test_iter.reset()\n",
    "            \n",
    "            \n",
    "            for modndx in range(num_models):\n",
    "                #Record testing loss and accuracy\n",
    "                exec('testing_loss{}.append(sum{}_loss/test_count)'.format(modndx+1,modndx+1))\n",
    "                exec('testing_accu{}.append(sum{}_accu/test_count)'.format(modndx+1,modndx+1))\n",
    "                \n",
    "                #Save model and optimizer state\n",
    "                exec('serializers.save_npz(os.path.join(out,\"MLP{}.model\"), model{})'.format(modndx+1,modndx+1))\n",
    "                exec('serializers.save_npz(os.path.join(out,\"MLP{}.state\"), optimizer{})'.format(modndx+1,modndx+1))\n",
    "                \n",
    "                #Save training data\n",
    "                exec('pickle.dump(training_loss{},open(os.path.join(out,\"training_loss{}.pkl\"),\"wb\"))'.format(modndx+1,modndx+1))\n",
    "                exec('pickle.dump(training_accu{},open(os.path.join(out,\"training_accu{}.pkl\"),\"wb\"))'.format(modndx+1,modndx+1))\n",
    "                \n",
    "                #Save testing data\n",
    "                exec('pickle.dump(testing_loss{},open(os.path.join(out,\"testing_loss{}.pkl\"),\"wb\"))'.format(modndx+1,modndx+1))\n",
    "                exec('pickle.dump(testing_accu{},open(os.path.join(out,\"testing_accu{}.pkl\"),\"wb\"))'.format(modndx+1,modndx+1))\n",
    "                \n",
    "                #Reinitialize for next training\n",
    "                exec('sum{}_loss = 0'.format(modndx+1))\n",
    "                exec('sum{}_accu = 0'.format(modndx+1))                \n",
    "            train_count = 0\n",
    "            \n",
    "            time_epoch = time.time() - time_start\n",
    "            log.write('epoch:{:04d} time elapsed:{:0.06f} sec \\r\\n'.format(train_iter.epoch+last_epoch, time_epoch))\n",
    "            log.flush()\n",
    "            print('epoch:{:04d} done time elapsed:{:0.06f} sec'.format(train_iter.epoch+last_epoch, time_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
